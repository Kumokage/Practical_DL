{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Deep Learning (7 points)\n",
    "\n",
    "Today we're gonna apply the newly learned DL tools for sequence processing to the task of predicting job salary.\n",
    "\n",
    "Special thanks to [Oleg Vasilev](https://github.com/Omrigan/) for the assignment core (orignally written for theano/tensorflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the challenge\n",
    "For starters, let's download the data from __[here](https://yadi.sk/d/vVEOWPFY3NruT7)__.\n",
    "\n",
    "You can also get it from the competition [page](https://www.kaggle.com/c/job-salary-prediction/data) (in that case, pick `Train_rev1.*`).\n",
    "\n",
    "\n",
    "Our task is to predict one number, __SalaryNormalized__, in the sense of minimizing __Mean Absolute Error__.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3342/media/salary%20prediction%20engine%20v2.png\" width=400px>\n",
    "\n",
    "To do so, our model ca access a number of features:\n",
    "* Free text: __`Title`__ and  __`FullDescription`__\n",
    "* Categorical: __`Category`__, __`Company`__, __`LocationNormalized`__, __`ContractType`__, and __`ContractTime`__.\n",
    "\n",
    "\n",
    "You can read more [in the official description](https://www.kaggle.com/c/job-salary-prediction#description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>Log1pSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127119</th>\n",
       "      <td>70028200</td>\n",
       "      <td>GRADUATE SALES EXECUTIVE</td>\n",
       "      <td>GRADUATE SALES EXECUTIVE Sector: Digital Media...</td>\n",
       "      <td>City London South East</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BMS Sales Specialists LLP</td>\n",
       "      <td>Sales Jobs</td>\n",
       "      <td>18000 per annum + bonus, benefits</td>\n",
       "      <td>18000</td>\n",
       "      <td>salestarget.co.uk</td>\n",
       "      <td>9.798182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13548</th>\n",
       "      <td>66606331</td>\n",
       "      <td>Java Developer (FX Options)  London  3 Months ...</td>\n",
       "      <td>I am currently looking for a Java Developer to...</td>\n",
       "      <td>City of London</td>\n",
       "      <td>The City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>400 - 401 per day</td>\n",
       "      <td>96120</td>\n",
       "      <td>theitjobboard.co.uk</td>\n",
       "      <td>11.473363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59831</th>\n",
       "      <td>68691929</td>\n",
       "      <td>Technical Support Specialist / Technical Analyst</td>\n",
       "      <td>Application Support Engineer / Technical Suppo...</td>\n",
       "      <td>Cambridge Cambridgeshire East Anglia</td>\n",
       "      <td>UK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Spring Technology</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>28000.00 - 30000.00 per annum</td>\n",
       "      <td>29000</td>\n",
       "      <td>totaljobs.com</td>\n",
       "      <td>10.275085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                                              Title  \\\n",
       "127119  70028200                           GRADUATE SALES EXECUTIVE   \n",
       "13548   66606331  Java Developer (FX Options)  London  3 Months ...   \n",
       "59831   68691929   Technical Support Specialist / Technical Analyst   \n",
       "\n",
       "                                          FullDescription  \\\n",
       "127119  GRADUATE SALES EXECUTIVE Sector: Digital Media...   \n",
       "13548   I am currently looking for a Java Developer to...   \n",
       "59831   Application Support Engineer / Technical Suppo...   \n",
       "\n",
       "                                 LocationRaw LocationNormalized ContractType  \\\n",
       "127119                City London South East             London          NaN   \n",
       "13548                         City of London           The City          NaN   \n",
       "59831   Cambridge Cambridgeshire East Anglia                 UK          NaN   \n",
       "\n",
       "       ContractTime                    Company    Category  \\\n",
       "127119          NaN  BMS Sales Specialists LLP  Sales Jobs   \n",
       "13548      contract                        NaN     IT Jobs   \n",
       "59831     permanent          Spring Technology     IT Jobs   \n",
       "\n",
       "                                SalaryRaw  SalaryNormalized  \\\n",
       "127119  18000 per annum + bonus, benefits             18000   \n",
       "13548                   400 - 401 per day             96120   \n",
       "59831       28000.00 - 30000.00 per annum             29000   \n",
       "\n",
       "                 SourceName  Log1pSalary  \n",
       "127119    salestarget.co.uk     9.798182  \n",
       "13548   theitjobboard.co.uk    11.473363  \n",
       "59831         totaljobs.com    10.275085  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "\n",
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\"\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast nan to string\n",
    "\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The NLP part\n",
    "\n",
    "To even begin training our neural network, we're gonna need to preprocess the text features: tokenize it and build the token vocabularies.\n",
    "\n",
    "Since it is not an NLP course, we're gonna use simple built-in NLTK tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "0         Engineering Systems Analyst\n",
      "100000                   HR Assistant\n",
      "200000           Senior EC&I Engineer\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Before\")\n",
    "print(data[\"Title\"][::100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "for col in text_columns:\n",
    "    data[col] = data[col].apply(lambda l: ' '.join(tokenizer.tokenize(str(l).lower())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can assume that our text is a space-separated list of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After\n",
      "0         engineering systems analyst\n",
      "100000                   hr assistant\n",
      "200000         senior ec & i engineer\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"After\")\n",
    "print(data[\"Title\"][::100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all words are equally useful. Some of them are typos or rare words that are only present a few times. \n",
    "\n",
    "Let's see how many times is each word present in the data so that we can build a \"white list\" of known words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>Log1pSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>engineering systems analyst</td>\n",
       "      <td>engineering systems analyst dorking surrey sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>10.126671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>stress engineer glasgow</td>\n",
       "      <td>stress engineer glasgow salary **** to **** we...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>10.308986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>modelling and simulation analyst</td>\n",
       "      <td>mathematical modeller / simulation analyst / o...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>10.308986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>engineering systems analyst / mathematical mod...</td>\n",
       "      <td>engineering systems analyst / mathematical mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>10.221977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>pioneer , miser engineering systems analyst</td>\n",
       "      <td>pioneer , miser engineering systems analyst do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>10.126671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244763</th>\n",
       "      <td>72705211</td>\n",
       "      <td>teacher of science</td>\n",
       "      <td>position : qualified teacher subject / special...</td>\n",
       "      <td>Swindon</td>\n",
       "      <td>Swindon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>450 - 500 per week</td>\n",
       "      <td>22800</td>\n",
       "      <td>hays.co.uk</td>\n",
       "      <td>10.034559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244764</th>\n",
       "      <td>72705212</td>\n",
       "      <td>teacher of business studies and ict</td>\n",
       "      <td>position : qualified teacher or nqt subject / ...</td>\n",
       "      <td>Swindon</td>\n",
       "      <td>Swindon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>450 - 500 per week</td>\n",
       "      <td>22800</td>\n",
       "      <td>hays.co.uk</td>\n",
       "      <td>10.034559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244765</th>\n",
       "      <td>72705213</td>\n",
       "      <td>english teacher</td>\n",
       "      <td>position : qualified teacher subject / special...</td>\n",
       "      <td>Swindon</td>\n",
       "      <td>Swindon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>450 - 500 per week</td>\n",
       "      <td>22800</td>\n",
       "      <td>hays.co.uk</td>\n",
       "      <td>10.034559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244766</th>\n",
       "      <td>72705216</td>\n",
       "      <td>supply teachers</td>\n",
       "      <td>position : qualified teacher subject / special...</td>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>450 to 500 per week</td>\n",
       "      <td>22800</td>\n",
       "      <td>hays.co.uk</td>\n",
       "      <td>10.034559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244767</th>\n",
       "      <td>72705235</td>\n",
       "      <td>accountant</td>\n",
       "      <td>this entrepreneurial and growing private equit...</td>\n",
       "      <td>Hitchin</td>\n",
       "      <td>Hitchin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>40-45,000</td>\n",
       "      <td>42500</td>\n",
       "      <td>hays.co.uk</td>\n",
       "      <td>10.657283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244768 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                                              Title  \\\n",
       "0       12612628                        engineering systems analyst   \n",
       "1       12612830                            stress engineer glasgow   \n",
       "2       12612844                   modelling and simulation analyst   \n",
       "3       12613049  engineering systems analyst / mathematical mod...   \n",
       "4       12613647        pioneer , miser engineering systems analyst   \n",
       "...          ...                                                ...   \n",
       "244763  72705211                                 teacher of science   \n",
       "244764  72705212                teacher of business studies and ict   \n",
       "244765  72705213                                    english teacher   \n",
       "244766  72705216                                    supply teachers   \n",
       "244767  72705235                                         accountant   \n",
       "\n",
       "                                          FullDescription  \\\n",
       "0       engineering systems analyst dorking surrey sal...   \n",
       "1       stress engineer glasgow salary **** to **** we...   \n",
       "2       mathematical modeller / simulation analyst / o...   \n",
       "3       engineering systems analyst / mathematical mod...   \n",
       "4       pioneer , miser engineering systems analyst do...   \n",
       "...                                                   ...   \n",
       "244763  position : qualified teacher subject / special...   \n",
       "244764  position : qualified teacher or nqt subject / ...   \n",
       "244765  position : qualified teacher subject / special...   \n",
       "244766  position : qualified teacher subject / special...   \n",
       "244767  this entrepreneurial and growing private equit...   \n",
       "\n",
       "                              LocationRaw LocationNormalized ContractType  \\\n",
       "0                 Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1             Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2       Hampshire, South East, South East          Hampshire          NaN   \n",
       "3          Surrey, South East, South East             Surrey          NaN   \n",
       "4          Surrey, South East, South East             Surrey          NaN   \n",
       "...                                   ...                ...          ...   \n",
       "244763                            Swindon            Swindon          NaN   \n",
       "244764                            Swindon            Swindon          NaN   \n",
       "244765                            Swindon            Swindon          NaN   \n",
       "244766                          Wiltshire          Wiltshire          NaN   \n",
       "244767                            Hitchin            Hitchin          NaN   \n",
       "\n",
       "       ContractTime                       Company          Category  \\\n",
       "0         permanent  Gregory Martin International  Engineering Jobs   \n",
       "1         permanent  Gregory Martin International  Engineering Jobs   \n",
       "2         permanent  Gregory Martin International  Engineering Jobs   \n",
       "3         permanent  Gregory Martin International  Engineering Jobs   \n",
       "4         permanent  Gregory Martin International  Engineering Jobs   \n",
       "...             ...                           ...               ...   \n",
       "244763     contract                           NaN     Teaching Jobs   \n",
       "244764     contract                           NaN     Teaching Jobs   \n",
       "244765     contract                           NaN     Teaching Jobs   \n",
       "244766     contract                           NaN     Teaching Jobs   \n",
       "244767    permanent                           NaN     Teaching Jobs   \n",
       "\n",
       "                                     SalaryRaw  SalaryNormalized  \\\n",
       "0                   20000 - 30000/annum 20-30K             25000   \n",
       "1                   25000 - 35000/annum 25-35K             30000   \n",
       "2                   20000 - 40000/annum 20-40K             30000   \n",
       "3       25000 - 30000/annum 25K-30K negotiable             27500   \n",
       "4                   20000 - 30000/annum 20-30K             25000   \n",
       "...                                        ...               ...   \n",
       "244763                      450 - 500 per week             22800   \n",
       "244764                      450 - 500 per week             22800   \n",
       "244765                      450 - 500 per week             22800   \n",
       "244766                     450 to 500 per week             22800   \n",
       "244767                               40-45,000             42500   \n",
       "\n",
       "              SourceName  Log1pSalary  \n",
       "0       cv-library.co.uk    10.126671  \n",
       "1       cv-library.co.uk    10.308986  \n",
       "2       cv-library.co.uk    10.308986  \n",
       "3       cv-library.co.uk    10.221977  \n",
       "4       cv-library.co.uk    10.126671  \n",
       "...                  ...          ...  \n",
       "244763        hays.co.uk    10.034559  \n",
       "244764        hays.co.uk    10.034559  \n",
       "244765        hays.co.uk    10.034559  \n",
       "244766        hays.co.uk    10.034559  \n",
       "244767        hays.co.uk    10.657283  \n",
       "\n",
       "[244768 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "token_counts = Counter()\n",
    "\n",
    "# Count how many times does each token occur in \"Title\" and \"FullDescription\"\n",
    "for row in data.iloc():\n",
    "    token_counts.update(row['Title'].split(' '))\n",
    "    token_counts.update(row['FullDescription'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 202704\n",
      "('and', 2657388)\n",
      "('.', 2523216)\n",
      "(',', 2318606)\n",
      "('the', 2080994)\n",
      "('to', 2019884)\n",
      "...\n",
      "('stephanietraveltraderecruitmnt', 1)\n",
      "('ruabon', 1)\n",
      "('lowehays', 1)\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Counts')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see how many words are there for each count\n",
    "\n",
    "_=plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
    "plt.xlabel(\"Counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1.1__ Get a list of all tokens that occur at least 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = list(map(lambda item: item[0], filter(lambda item: item[1] >= min_count, token_counts.items())))\n",
    "\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens left: 34158\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens left:\", len(tokens))\n",
    "assert type(tokens)==list\n",
    "assert len(tokens) in range(32000,35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1.2__ Build an inverse token index: a dictionary from token(string) to it's index in `tokens` (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {tokens[i]: i for i in range(len(tokens))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's use the vocabulary you've built to map text lines into torch-digestible matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[    2     3     4     1     1]\n",
      " [  550  2380     1     1     1]\n",
      " [  320 10714   392   307    32]]\n"
     ]
    }
   ],
   "source": [
    "#### print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's  encode the categirical data we have.\n",
    "\n",
    "As usual, we shall use one-hot encoding for simplicity. Kudos if you implement tf-idf, target averaging or pseudo-counter-based encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data science part\n",
    "\n",
    "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
    "\n",
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  220291\n",
      "Validation size =  24477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch(data, batch_size=None, replace=True, max_len=None):\n",
    "    \"\"\"\n",
    "    Creates a pytorch-friendly dict from the batch data.\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    if batch_size is not None:\n",
    "        data = data.sample(batch_size, replace=replace)\n",
    "    \n",
    "    batch = {}\n",
    "    for col in text_columns:\n",
    "        batch[col] = as_matrix(data[col].values, max_len)\n",
    "    \n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': array([[2380,  901,   19, 1897,  822, 1382,   14, 1664],\n",
       "        [ 297,   22,  345,  901,    1,    1,    1,    1],\n",
       "        [2176,  393,  130,  113,  655,   32,    1,    1]], dtype=int32),\n",
       " 'FullDescription': array([[ 170,   12,   44,  434,  778, 3266,  822, 1382,   62,  105],\n",
       "        [ 297,  345,  901,   22, 1040,   44, 2405, 1767,   66,  188],\n",
       "        [  10,   11,   12,   44,  563,  461, 2905,  308,  337,  327]],\n",
       "       dtype=int32),\n",
       " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'Log1pSalary': array([ 9.998843, 10.71444 , 10.389026], dtype=float32)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_batch(data_train, 3, max_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's talk deep learning\n",
    "\n",
    "Out model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "![scheme](https://github.com/yandexdataschool/Practical_DL/raw/master/homework04/conv_salary_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, both text vectorizers shall use 1d convolutions, followed by global pooling over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader \n",
    "embeddings = gensim.downloader.load(\"fasttext-wiki-news-subwords-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class GlobalMaxPooling(nn.Module):\n",
    "    def __init__(self, dim=-1):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.max(dim=self.dim)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAvgPooling(nn.Module):\n",
    "    def __init__(self, dim=-1):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.sum(dim=self.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TitleEncoder(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), out_size=64, pretrained_weights=None, is_tune=False):\n",
    "        \"\"\"\n",
    "        A simple sequential encoder for titles.\n",
    "        x -> emb -> conv -> global_max -> relu -> dense\n",
    "        \"\"\"\n",
    "        super(self.__class__, self).__init__()\n",
    "        if pretrained_weights is not None:\n",
    "            self.emb = nn.Embedding.from_pretrained(pretrained_weights)\n",
    "            self.emb.requires_grad_(is_tune)\n",
    "        else:\n",
    "            self.emb = nn.Embedding(n_tokens, 300, padding_idx=PAD_IX)\n",
    "        self.conv1 = nn.Conv1d(300, 150, kernel_size=3, padding=1)\n",
    "        self.batch1 = nn.BatchNorm1d(150)\n",
    "        self.conv2 = nn.Conv1d(150, out_size, kernel_size=3, padding=1)\n",
    "        self.pool1 = GlobalMaxPooling()\n",
    "        self.dense = nn.Linear(out_size, out_size)\n",
    "\n",
    "    def forward(self, text_ix):\n",
    "        \"\"\"\n",
    "        :param text_ix: int64 Variable of shape [batch_size, max_len]\n",
    "        :returns: float32 Variable of shape [batch_size, out_size]\n",
    "        \"\"\"\n",
    "        h = self.emb(text_ix)\n",
    "\n",
    "        # we transpose from [batch, time, units] to [batch, units, time] to fit Conv1d dim order\n",
    "        h = torch.transpose(h, 1, 2)\n",
    "        \n",
    "        # Apply the layers as defined above. Add some ReLUs before dense.\n",
    "        h = self.conv1(h)\n",
    "        h = self.batch1(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.pool1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.dense(h)\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine\n"
     ]
    }
   ],
   "source": [
    "title_encoder = TitleEncoder(pretrained_weights=torch.FloatTensor(embeddings.vectors))\n",
    "\n",
    "dummy_x = Variable(torch.LongTensor(generate_batch(data_train, 3)['Title']))\n",
    "dummy_v = title_encoder(dummy_x)\n",
    "\n",
    "assert isinstance(dummy_v, Variable)\n",
    "assert tuple(dummy_v.shape) == (dummy_x.shape[0], 64)\n",
    "\n",
    "del title_encoder\n",
    "print(\"Seems fine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.1__ Create description encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define an encoder for job descriptions.\n",
    "# Use any means you want so long as it's torch.nn.Module.\n",
    "class DescriptionsEncoder(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), out_size=64, pretrained_weights=None, is_tune=False):\n",
    "        \"\"\" \n",
    "        A simple sequential encoder for descriptions.\n",
    "        x -> emb -> conv -> global_max -> relu -> dense\n",
    "        \"\"\"\n",
    "        super(self.__class__, self).__init__()\n",
    "        if pretrained_weights is not None:\n",
    "            self.emb = nn.Embedding.from_pretrained(pretrained_weights)\n",
    "            self.emb.requires_grad_(is_tune)\n",
    "        else:\n",
    "            self.emb = nn.Embedding(n_tokens, 300, padding_idx=PAD_IX)\n",
    "        self.conv1 = nn.Conv1d(300, 150, kernel_size=3, padding=1)\n",
    "        self.batch1 = nn.BatchNorm1d(150)\n",
    "        self.conv2 = nn.Conv1d(150, out_size, kernel_size=3, padding=1)\n",
    "        self.pool1 = GlobalMaxPooling()  \n",
    "        self.dense = nn.Linear(out_size, out_size)\n",
    "\n",
    "    def forward(self, text_ix):\n",
    "        \"\"\"\n",
    "        :param text_ix: int64 Variable of shape [batch_size, max_len]\n",
    "        :returns: float32 Variable of shape [batch_size, out_size]\n",
    "        \"\"\"\n",
    "        h = self.emb(text_ix)\n",
    "\n",
    "        # we transpose from [batch, time, units] to [batch, units, time] to fit Conv1d dim order\n",
    "        h = torch.transpose(h, 1, 2)\n",
    "        \n",
    "        # Apply the layers as defined above. Add some ReLUs before dense.\n",
    "        h = self.conv1(h)\n",
    "        h = self.batch1(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.pool1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.dense(h)\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine too\n"
     ]
    }
   ],
   "source": [
    "desc_encoder = DescriptionsEncoder(pretrained_weights=torch.FloatTensor(embeddings.vectors))\n",
    "\n",
    "dummy_x = Variable(torch.LongTensor(generate_batch(data_train, 3)['FullDescription']))\n",
    "dummy_v = desc_encoder(dummy_x)\n",
    "\n",
    "assert isinstance(dummy_v, Variable)\n",
    "assert tuple(dummy_v.shape) == (dummy_x.shape[0], 64)\n",
    "del desc_encoder\n",
    "print(\"Seems fine too\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Task 2.2__ Build one network ~~to rule them all~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FullNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    This class does all the steps from (title, desc, categorical) features -> predicted target\n",
    "    It unites title & desc encoders you defined above as long as some layers for head and categorical branch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), is_tune=False, pretrained_weights=None):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "        self.title_encoder = TitleEncoder(out_size=300, pretrained_weights=pretrained_weights, is_tune=is_tune).to(device)\n",
    "        self.desc_encoder = DescriptionsEncoder(out_size=300, pretrained_weights=pretrained_weights, is_tune=is_tune).to(device)\n",
    "        \n",
    "        # define layers for categorical features. A few dense layers would do.\n",
    "        self.dense1 = nn.Linear(n_cat_features, 128)\n",
    "        self.dense2 = nn.Linear(128, 64)\n",
    "        self.batch1 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        # define \"output\" layers that process depend the three encoded vectors into answer\n",
    "        self.dense3 = nn.Linear(664, 332)\n",
    "        self.batch2 = nn.BatchNorm1d(332)\n",
    "        self.dense4 = nn.Linear(332, 166)\n",
    "        self.dense5 = nn.Linear(166, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, title_ix, desc_ix, cat_features):\n",
    "        \"\"\"\n",
    "        :param title_ix: int32 Variable [batch, title_len], job titles encoded by as_matrix\n",
    "        :param desc_ix:  int32 Variable [batch, desc_len] , job descriptions encoded by as_matrix\n",
    "        :param cat_features: float32 Variable [batch, n_cat_features]\n",
    "        :returns: float32 Variable 1d [batch], predicted log1p-salary\n",
    "        \"\"\"\n",
    "        \n",
    "        # process each data source with it's respective encoder\n",
    "        title_h = self.title_encoder(title_ix)\n",
    "        title_h = F.dropout(title_h, p=0.1)\n",
    "        desc_h = self.desc_encoder(desc_ix)\n",
    "        desc_h = F.dropout(desc_h, p=0.1)\n",
    "        \n",
    "        # apply categorical encoder\n",
    "        cat_h = self.dense1(cat_features)\n",
    "        cat_h = F.relu(cat_h)\n",
    "        cat_h = self.dense2(cat_h)\n",
    "        cat_h = self.batch1(cat_h)\n",
    "        \n",
    "        # concatenate all vectors together...\n",
    "        joint_h = torch.cat([title_h, desc_h, cat_h], dim=1)\n",
    "        \n",
    "        # ... and stack a few more layers at the top\n",
    "        h = self.dense3(joint_h)\n",
    "        h = self.batch2(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=0.1)\n",
    "        h = self.dense4(h)\n",
    "        h = self.dense5(h)\n",
    "        \n",
    "        # Note 1: do not forget to select first columns, [:, 0], to get to 1d outputs\n",
    "        # Note 2: please do not use output nonlinearities.\n",
    "        \n",
    "        return h[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = FullNetwork(pretrained_weights=torch.FloatTensor(embeddings.vectors), is_tune=True).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test it on one batch\n",
    "\n",
    "batch = generate_batch(data_train, 32)\n",
    "\n",
    "title_ix = Variable(torch.LongTensor(batch[\"Title\"])).to(device)\n",
    "desc_ix = Variable(torch.LongTensor(batch[\"FullDescription\"])).to(device)\n",
    "cat_features = Variable(torch.FloatTensor(batch[\"Categorical\"])).to(device)\n",
    "reference = Variable(torch.FloatTensor(batch[target_column])).to(device)\n",
    "\n",
    "prediction = model(title_ix, desc_ix, cat_features).to(device)\n",
    "\n",
    "assert len(prediction.shape) == 1 and prediction.shape[0] == title_ix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(reference, prediction):\n",
    "    \"\"\"\n",
    "    Computes objective for minimization.\n",
    "    By deafult we minimize MSE, but you are encouraged to try mix up MSE, MAE, huber loss, etc.\n",
    "    \"\"\"\n",
    "    return torch.mean((prediction - reference) ** 2)\n",
    "\n",
    "def compute_mae(reference, prediction):\n",
    "    \"\"\" Compute MAE on actual salary, assuming your model outputs log1p(salary)\"\"\"\n",
    "    return torch.abs(torch.exp(reference - 1) - torch.exp(prediction - 1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = compute_loss(reference, prediction)\n",
    "dummy_grads = torch.autograd.grad(loss, model.parameters(), retain_graph=True)\n",
    "for grad in dummy_grads:\n",
    "    assert grad is not None and not (grad == 0).all(), \"Some model parameters received zero grads. \" \\\n",
    "                                                       \"Double-check that your model uses all it's layers.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullNetwork(pretrained_weights=torch.FloatTensor(embeddings.vectors)).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "def iterate_minibatches(data, batch_size=32, max_len=None,\n",
    "                        max_batches=None, shuffle=True, verbose=True):\n",
    "    indices = np.arange(len(data))\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(indices)\n",
    "    if max_batches is not None:\n",
    "        indices = indices[: batch_size * max_batches]\n",
    "        \n",
    "    irange = trange if verbose else range\n",
    "    \n",
    "    for start in irange(0, len(indices), batch_size):\n",
    "        yield generate_batch(data.iloc[indices[start : start + batch_size]], max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "max_len = 100\n",
    "batch_size = 32\n",
    "batches_per_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullNetwork(\n",
       "  (title_encoder): TitleEncoder(\n",
       "    (emb): Embedding(999999, 300)\n",
       "    (conv1): Conv1d(300, 150, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (batch1): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(150, 300, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (pool1): GlobalMaxPooling()\n",
       "    (dense): Linear(in_features=300, out_features=300, bias=True)\n",
       "  )\n",
       "  (desc_encoder): DescriptionsEncoder(\n",
       "    (emb): Embedding(999999, 300)\n",
       "    (conv1): Conv1d(300, 150, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (batch1): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(150, 300, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (pool1): GlobalMaxPooling()\n",
       "    (dense): Linear(in_features=300, out_features=300, bias=True)\n",
       "  )\n",
       "  (dense1): Linear(in_features=3768, out_features=128, bias=True)\n",
       "  (dense2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (batch1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dense3): Linear(in_features=664, out_features=332, bias=True)\n",
       "  (batch2): BatchNorm1d(332, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dense4): Linear(in_features=332, out_features=166, bias=True)\n",
       "  (dense5): Linear(in_features=166, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 0:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06971ec792874dcd9d34f301c1276c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t7.19021\n",
      "\tMAE:\t628898.31695\n",
      "Validation 0:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18159634a5e4804880b0aaee783bbe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t5.60042\n",
      "\tMAE:\t208333.14200\n",
      "\n",
      "New best epoch!\n",
      "Training 1:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ff98fef74c46f0b9f536fca9228eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t1.48357\n",
      "\tMAE:\t17501.79312\n",
      "Validation 1:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227b6d2e9020470cb579a8efc8c73487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t12.94548\n",
      "\tMAE:\t722318.46773\n",
      "\n",
      "Training 2:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef124fdef472498384d0c9755756f828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t1.09642\n",
      "\tMAE:\t12573.37054\n",
      "Validation 2:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4f0332e0dc404c8510d4980f2c9fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t9.67362\n",
      "\tMAE:\t349400.55270\n",
      "\n",
      "Training 3:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31b248ca91d4b6cae9a198a801c48b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.92884\n",
      "\tMAE:\t11826.77794\n",
      "Validation 3:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a3b73141ae48cf872ef4835dd34c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t1.39603\n",
      "\tMAE:\t8277.74581\n",
      "\n",
      "New best epoch!\n",
      "Training 4:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01465c5a65214dc1aced99ad3f6a60ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.85143\n",
      "\tMAE:\t10420.37697\n",
      "Validation 4:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5d374db2b840c6b05cba09491c8e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.89936\n",
      "\tMAE:\t8102.72021\n",
      "\n",
      "New best epoch!\n",
      "Training 5:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da770b7c42d74a48ba318b30f9fa883d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.77624\n",
      "\tMAE:\t9346.33744\n",
      "Validation 5:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19a426cda594db9ae5c072298865cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.78154\n",
      "\tMAE:\t12905.69618\n",
      "\n",
      "Training 6:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e045b8e435f416fa727b939c8cee165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.80748\n",
      "\tMAE:\t12123.50794\n",
      "Validation 6:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2c746535884bfda9b8fcb498351c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t5.76882\n",
      "\tMAE:\t136071.23258\n",
      "\n",
      "Training 7:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1a3a3531b845fa8a1f37fbef81da27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.70516\n",
      "\tMAE:\t9062.31425\n",
      "Validation 7:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb4722800c146189642293ad767c947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.59999\n",
      "\tMAE:\t6668.32413\n",
      "\n",
      "New best epoch!\n",
      "Training 8:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c259360cd074a0ab999ea679f508297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.60089\n",
      "\tMAE:\t8213.05621\n",
      "Validation 8:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d9229354bf4b44a48821090cb85d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t5.46094\n",
      "\tMAE:\t124173.44458\n",
      "\n",
      "Training 9:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937386d1e1f44d6d84c78b204a70f7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.57184\n",
      "\tMAE:\t8550.54637\n",
      "Validation 9:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94bc20a0fa134a5faaaa35602ce0cf45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.77551\n",
      "\tMAE:\t6572.24500\n",
      "\n",
      "New best epoch!\n",
      "Training 10:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a1ed59766e453cb723b592dcb34ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.59284\n",
      "\tMAE:\t8121.95183\n",
      "Validation 10:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2344ae74f94384aa3df7a7e077a2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t5.06587\n",
      "\tMAE:\t111383.39467\n",
      "\n",
      "Training 11:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ca506e163648c199d09b7f3f9909b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.55423\n",
      "\tMAE:\t7728.22910\n",
      "Validation 11:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe934e93b9f541ccab086aa029a40ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.51966\n",
      "\tMAE:\t9195.80757\n",
      "\n",
      "Training 12:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea3bc4ad6f1405d881cd68813dc1fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.51898\n",
      "\tMAE:\t7202.86308\n",
      "Validation 12:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8daec237f8e4ce9ace3261b6789e2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.61420\n",
      "\tMAE:\t6490.65255\n",
      "\n",
      "New best epoch!\n",
      "Training 13:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66de8d41c0f04a70a30f0eb50c3069de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.51616\n",
      "\tMAE:\t7426.36566\n",
      "Validation 13:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc88c36c69ec4d0b913074f2401356d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.42282\n",
      "\tMAE:\t7554.43460\n",
      "\n",
      "Training 14:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef21dd362dd40b6bf82b2e1f322f206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.49266\n",
      "\tMAE:\t7247.56940\n",
      "Validation 14:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4511746f022d45e3be9b920512b57d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.61961\n",
      "\tMAE:\t6157.45503\n",
      "\n",
      "New best epoch!\n",
      "Training 15:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29fe04d9e0ab483fbdb2fbf1181f4fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.50763\n",
      "\tMAE:\t7518.09855\n",
      "Validation 15:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc9106064bf44c0be6b48647bb266dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.36535\n",
      "\tMAE:\t5919.80243\n",
      "\n",
      "New best epoch!\n",
      "Training 16:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf6898260454a48966318f9158fd8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.45831\n",
      "\tMAE:\t6993.67964\n",
      "Validation 16:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e94b9eb7e64d18ab36be3eea79e69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.35871\n",
      "\tMAE:\t6056.57679\n",
      "\n",
      "Training 17:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c58be5aa0e4aefb956d08e6f77272a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.41774\n",
      "\tMAE:\t6532.41302\n",
      "Validation 17:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7198e74765408e8fd1867cdd4e8158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.56211\n",
      "\tMAE:\t10307.00650\n",
      "\n",
      "Training 18:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6209a00a6cbf4697bd963b140fc0957d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.50181\n",
      "\tMAE:\t7421.97748\n",
      "Validation 18:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58db0111d2b4486f96de6b6266eb72f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.34268\n",
      "\tMAE:\t5471.82057\n",
      "\n",
      "New best epoch!\n",
      "Training 19:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9be9d14640944f388b689da3085c318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.50386\n",
      "\tMAE:\t7438.98516\n",
      "Validation 19:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f63a101779f461fb029ea552f7606ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t2.58831\n",
      "\tMAE:\t9470.98923\n",
      "\n",
      "Training 20:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2b3133563c4db4bd225ff9f6a935a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.48665\n",
      "\tMAE:\t7431.60433\n",
      "Validation 20:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02eb7194b6b74fd3a5cf77fcb1788f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.43195\n",
      "\tMAE:\t8173.60106\n",
      "\n",
      "Training 21:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a411c0600e7f4c96a75add009555cbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.40334\n",
      "\tMAE:\t6637.60173\n",
      "Validation 21:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3daf55bd1d4a0abf289858b4c134b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t1.14653\n",
      "\tMAE:\t20501.98436\n",
      "\n",
      "Training 22:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e54afebe0f41968d5b246558b6784f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.43612\n",
      "\tMAE:\t6890.85263\n",
      "Validation 22:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7b9a3028284905a72b646213771f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t5.10462\n",
      "\tMAE:\t10993.25379\n",
      "\n",
      "Training 23:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c2e3f078e94e0590fcc1d0d722b0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.40794\n",
      "\tMAE:\t6462.15354\n",
      "Validation 23:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f0703d546b4e57be17b67346b92fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.33704\n",
      "\tMAE:\t5755.49420\n",
      "\n",
      "Training 24:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69496a24036f4aefa5eb52d6400f6ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.39743\n",
      "\tMAE:\t6406.36969\n",
      "Validation 24:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebaa6c0dbf884dd9833446e1923f2d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.30208\n",
      "\tMAE:\t5762.05672\n",
      "\n",
      "Training 25:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7dc81ee0844cfb9c34b1e5deb18ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.37307\n",
      "\tMAE:\t6124.74368\n",
      "Validation 25:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7d9938df804a79bc724dd9f825cf48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.30740\n",
      "\tMAE:\t5090.99257\n",
      "\n",
      "New best epoch!\n",
      "Training 26:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004c1287db9e4fd4beb90ba544b5f4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.41331\n",
      "\tMAE:\t6659.15376\n",
      "Validation 26:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6021829d36cc40ca855c2ade5d479770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.31166\n",
      "\tMAE:\t5657.44185\n",
      "\n",
      "Training 27:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6d5656da1342d3881392ece258bde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.40553\n",
      "\tMAE:\t6607.05696\n",
      "Validation 27:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbaabaefce76455eac6f242e7135d25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.33883\n",
      "\tMAE:\t5066.81282\n",
      "\n",
      "New best epoch!\n",
      "Training 28:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8545b69e0a4c2db70b4053403b2026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.39113\n",
      "\tMAE:\t6369.10134\n",
      "Validation 28:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd68e88fcd2a48358bbdba4f67b72819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.29951\n",
      "\tMAE:\t5908.38836\n",
      "\n",
      "Training 29:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3096a403ebd4ff0b52ba4cfbd2d5f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.34691\n",
      "\tMAE:\t5893.69483\n",
      "Validation 29:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23ffa3fec92472e9b1b6d20300dc95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.33263\n",
      "\tMAE:\t6800.60766\n",
      "\n",
      "Training 30:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bebe151b2a46d6a2d29923cadc59b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.36178\n",
      "\tMAE:\t6016.44623\n",
      "Validation 30:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3081200c054494b3cd684d5764518e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.35545\n",
      "\tMAE:\t7206.12220\n",
      "\n",
      "Training 31:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1040a2b891499f9e86d0fab2540c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.33407\n",
      "\tMAE:\t5842.49643\n",
      "Validation 31:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52df1c825e641b89e8d6876a7fb6056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "best_mae = np.inf\n",
    "best_epoch = 0\n",
    "\n",
    "val_loss_list = []\n",
    "\n",
    "for epoch_i in range(num_epochs):\n",
    "    \n",
    "    print(f\"Training {epoch_i}:\")\n",
    "    train_loss = train_mae = train_batches = 0    \n",
    "    model.train(True)\n",
    "    \n",
    "    for batch in iterate_minibatches(data_train, max_batches=batches_per_epoch):\n",
    "\n",
    "        title_ix = Variable(torch.LongTensor(batch[\"Title\"])).to(device)\n",
    "        desc_ix = Variable(torch.LongTensor(batch[\"FullDescription\"])).to(device)\n",
    "        cat_features = Variable(torch.FloatTensor(batch[\"Categorical\"])).to(device)\n",
    "        reference = Variable(torch.FloatTensor(batch[target_column])).to(device)\n",
    "\n",
    "        prediction = model(title_ix, desc_ix, cat_features)\n",
    "\n",
    "        loss = compute_loss(reference, prediction)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        train_loss += loss.cpu().data.numpy()\n",
    "        train_mae += compute_mae(reference, prediction).cpu().data.numpy()\n",
    "        train_batches += 1\n",
    "    \n",
    "    print(\"\\tLoss:\\t%.5f\" % (train_loss / train_batches))\n",
    "    print(\"\\tMAE:\\t%.5f\" % (train_mae / train_batches))\n",
    "    \n",
    "    print(f\"Validation {epoch_i}:\")\n",
    "    val_loss = val_mae = val_batches = 0\n",
    "    model.train(False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterate_minibatches(data_val, shuffle=False):\n",
    "            title_ix = Variable(torch.LongTensor(batch[\"Title\"])).to(device)\n",
    "            desc_ix = Variable(torch.LongTensor(batch[\"FullDescription\"])).to(device)\n",
    "            cat_features = Variable(torch.FloatTensor(batch[\"Categorical\"])).to(device)\n",
    "            reference = Variable(torch.FloatTensor(batch[target_column])).to(device)\n",
    "\n",
    "            prediction = model(title_ix, desc_ix, cat_features)\n",
    "            loss = compute_loss(reference, prediction)\n",
    "\n",
    "            val_loss += loss.cpu().data.numpy()\n",
    "            val_mae += compute_mae(reference, prediction).cpu().data.numpy()\n",
    "            val_batches += 1\n",
    "\n",
    "    print(\"\\tLoss:\\t%.5f\" % (val_loss / val_batches))\n",
    "    print(\"\\tMAE:\\t%.5f\" % (val_mae / val_batches))\n",
    "    print(\"\")\n",
    "    \n",
    "    if (val_mae / val_batches) < best_mae:\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        best_epoch = epoch_i\n",
    "        best_mae = (val_mae / val_batches)\n",
    "        print(\"New best epoch!\")\n",
    "\n",
    "    if epoch_i > best_epoch + 10:\n",
    "        print(\"Early stop!\")\n",
    "        break\n",
    "\n",
    "    val_loss_list.append(val_loss / val_batches)\n",
    "    \n",
    "plt.plot(range(len(val_loss_list)), val_loss_list)\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "plt.show()\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eval:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0d396e9527408aa510bed8144207af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:\t0.08315\n",
      "\tMAE:\t2735.82698\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Final eval:\")\n",
    "val_loss = val_mae = val_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in iterate_minibatches(data_val, shuffle=False):\n",
    "        title_ix = Variable(torch.LongTensor(batch[\"Title\"])).to(device)\n",
    "        desc_ix = Variable(torch.LongTensor(batch[\"FullDescription\"])).to(device)\n",
    "        cat_features = Variable(torch.FloatTensor(batch[\"Categorical\"])).to(device)\n",
    "        reference = Variable(torch.FloatTensor(batch[target_column])).to(device)\n",
    "\n",
    "        prediction = model(title_ix, desc_ix, cat_features)\n",
    "        loss = compute_loss(reference, prediction)\n",
    "\n",
    "        val_loss += loss.cpu().data.numpy()\n",
    "        val_mae += compute_mae(reference, prediction).cpu().data.numpy()\n",
    "        val_batches += 1\n",
    "\n",
    "print(\"\\tLoss:\\t%.5f\" % (val_loss / val_batches))\n",
    "print(\"\\tMAE:\\t%.5f\" % (val_mae / val_batches))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Actually make it work\n",
    "\n",
    "Your main task is to use some of the tricks you've learned on the network and analyze if you can improve __validation MAE__.\n",
    "\n",
    "Try __at least 3 options__ from the list below for a passing grade. If you're into \n",
    "\n",
    "#### A) CNN architecture\n",
    "\n",
    "All the tricks you know about dense and convolutional neural networks apply here as well.\n",
    "* Dropout. Nuff said.\n",
    "* Batch Norm. This time it's `nn.BatchNorm1d`\n",
    "* Parallel convolution layers. The idea is that you apply several nn.Conv1d to the same embeddings and concatenate output channels.\n",
    "* More layers, more neurons, ya know...\n",
    "\n",
    "\n",
    "#### B) Play with pooling\n",
    "\n",
    "There's more than one way to do max pooling:\n",
    "* Max over time - our `GlobalMaxPooling`\n",
    "* Average over time (excluding PAD)\n",
    "* Softmax-pooling:\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot {{e ^ {h_{i, t}}} \\over \\sum_\\tau e ^ {h_{j, \\tau}} } }$$\n",
    "\n",
    "* Attentive pooling\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot Attn(h_t)}$$\n",
    "\n",
    ", where $$ Attn(h_t) = {{e ^ {NN_{attn}(h_t)}} \\over \\sum_\\tau e ^ {NN_{attn}(h_\\tau)}}  $$\n",
    "and $NN_{attn}$ is a small neural network\n",
    "\n",
    "\n",
    "The optimal score is usually achieved by concatenating several different poolings, including several attentive pooling with different $NN_{attn}$\n",
    "\n",
    "#### C) Fun with embeddings\n",
    "\n",
    "It's not always a good idea to train embeddings from scratch. Here's a few tricks:\n",
    "\n",
    "* Use a pre-trained word2vec from [here](http://ahogrammer.com/2017/01/20/the-list-of-pretrained-word-embeddings/) or [here](http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/).\n",
    "* Start with pre-trained embeddings, then fine-tune them with gradient descent\n",
    "* Use the same embedding matrix in title and desc vectorizer\n",
    "\n",
    "#### D) Going recurrent\n",
    "\n",
    "We've already learned that recurrent networks can do cool stuff in sequence modelling. Turns out, they're not useless for classification as well. With some tricks of course..\n",
    "\n",
    "* Like convolutional layers, LSTM should be pooled into a fixed-size vector with some of the poolings.\n",
    "  * Please bear in mind that while convolution uses [batch, units, time] dim order, \n",
    "    recurrent units are built for [batch, time, unit]. You may need to `torch.transpose`.\n",
    "\n",
    "* Since you know all the text in advance, use bidirectional RNN\n",
    "  * Run one LSTM from left to right\n",
    "  * Run another in parallel from right to left \n",
    "  * Concatenate their output sequences along unit axis (dim=-1)\n",
    "\n",
    "* It might be good idea to mix convolutions and recurrent layers differently for title and description\n",
    "\n",
    "\n",
    "#### E) Optimizing seriously\n",
    "\n",
    "* You don't necessarily need 100 epochs. Use early stopping. If you've never done this before, take a look at [keras](https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L461) for inspiration.\n",
    "  * In short, train until you notice that validation\n",
    "  * Maintain the best-on-validation snapshot via `model.state_dict`\n",
    "  * Plotting learning curves is usually a good idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A short report\n",
    "\n",
    "Please tell us what you did and how did it work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Improvement of base model\n",
    "Base model _MAE_: 3279.18025. \n",
    "1. First of all, let's do our training more efficient and more fast. We will stop if MAE don't improve for 10 epoch and use model from best epoch and raw loss curve.\n",
    "Also let's transfer our learning to GPU this will make it more fast and we will faster see further improvement. Model MAE after 1 step: 2659.21828.\n",
    "2. Some dropout and batches give MAE 3612.81334\n",
    "3. Implement AvgPooling, add it to TitleEmbeddings and DescriptionEmbedding MAE: 35758.90582\n",
    "4. Use gensim model `glove-wiki-gigaword-300` for pretraining embedding and also add more conv layers and change size for model working. MAE: 5066.81282\n",
    "\n",
    "Last step should learn really long, so i stop it after 30 epoch with MAE above. Also there are option for tuning pretrained weights, but it learn twice longer so i didn't manage to create appropriate run.\n",
    "From my tests i manage to create base model with early stop with MAE 2659.21828, other approaches wasn't so successful. But may be with longer learning stage can give something good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
